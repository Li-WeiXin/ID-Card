# ID-Card
给定一张身份证正、反面，识别身份证上的所有文字信息。
身份证项目总结
——用深度学习做文字识别相关的项目
技术流程：
首先是检测字符区域，然后进行水平切割，得到整行的文字，其次要考虑的就是怎么将每一个字符分开，并且从图片中切割下来，然后才可以导入训练好的模型进行字符识别。
引言：
项目的一开始，我先首先查阅了国内关于文本识别相关的api接口，发现网上的接口调用均是按次收费的，个人小规模的使用不成问题，但运用到商业上是一笔不小的费用。因此这个文本识别项目的具有一定的商业价值。
第一阶段：
首先我基于开源计算机视觉库opencv，尝试从图形处理的角度完成文本识别，通过对图片灰度化、二值化、高斯滤波、腐蚀、膨胀，处理，再使用封装好的pytesseract模块进行识别，识别效果如下：
 
使用这个方法有如下几个弊端：
	1、在识别前做的特征提取工作是根据膨胀后的大小框选的，换言之，只适用特定图片的特定部分检测，不具备通用文本检测功能。
	2、使用pytesseract识别模块，受限于识别模块的识别功能。识别功能不能做优化已完成自己项目的任务需要。
因此两点，开始尝试使用深度学习的方法解决遇到的问题。
第二阶段：
针对在第一阶段遇到的问题，查阅了相关论文资料，深度学习将从接下来几个步骤来寻求突破。
2.1 训练集的问题
使用深度学习第一步就是要有数据集，但是获得大量原身份证图片做研究这是不可能的，因此尝试从别的角度获得数据集。身份证上为印刷字体，故训练一个专门用于识别印刷汉字的模型。
	依据国标，一级字库为3755个常用汉字，所以我打算构建这3755个汉字的模型。
 
使用汉字旋转，增加噪声，随机位移，膨胀等图像变化等数据增强技术，得到图片近200万张。
之后由于身份证地址中存在阿拉伯数字混杂的识别情况，故在训练集中加入数字：
 
训练集构建完毕，在LeNet模型下，对于单个字识别效果较好。

2.2 文本检测
为了实现通用文本检测（即在一张图片中找出文字区域），常用方法是CTPN文本检测，模型是VGG16，进行了复现，效果如下：
  、 
2.3 单字切割
在文本检测完成后，水平切割出图片，还不能送入模型中完成识别，因为模型仅适用于单字的识别，这时要做的就是单字的分割，可以用opencv实现。
 
在完成分割后送入模型完成识别。

至此，项目流程总结如下：
1、CTPN文本检测模型（VGG16）
2、在字符单个切割的切割的过程中，使用OpenCV来实现
3、基于LeNet文本识别模型

项目中存在的问题及改进:
1、此方案最大的优势在于文本检测模型，却也受限于它的精度:
 
如果在第一步文本检测出现错误，将直接导致识别失败。
这种问题的出现一部分是由于训练集不全是由证件图片组成的，还有就是网络优化不够，这一块在优化后可以不断提高精度，由于训练集很大，需要在专门的GPU上训练才能减少训练成本。
2、单字分割，由于身份证项目（证件中）不存在字符的问题，分割模型已可以达到好的效果，不用优化。
3、识别模型，识别模型目前是在常用3000多汉字+10个数字组成的，日常使用可以，但应用于商业。精度明显不够，但优化方案易于实现，增加更多的文字，组成字典映射，通过数据增强生成训练集，导入模型训练即可。但是随着数据集的扩大，训练集的大幅增加，需要更换更深的网络，也对计算机的计算性能要求较高。




